{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#62分类正常\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "import TFRtools\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "lr = 1e-3\n",
    "# 生成相关目录保存生成信息\n",
    "def GEN_DIR():\n",
    "    import os\n",
    "    if not os.path.isdir('ckpt'):\n",
    "        print('文件夹ckpt未创建，现在在当前目录下创建..')\n",
    "        os.mkdir('ckpt')\n",
    "    if not os.path.isdir('trainLog'):\n",
    "        print('文件夹ckpt未创建，现在在当前目录下创建..')\n",
    "        os.mkdir('trainLog')\n",
    "\n",
    "\"\"\"\n",
    "#********************* CNN架构 *********************************\n",
    "\n",
    "输入：\n",
    "    x:[-1,32,32,1] 输入图像\n",
    "    y_:[-1,62]     标签\n",
    "CNN:\n",
    "    CONV1: w(3x3),stride = 1,pad = 'same',fmaps = 32 ([-1,16,16,32])\n",
    "    POOL1: p(2x2),stride = 2,pad = 'same'\n",
    "    RELU\n",
    "    \n",
    "    CONV2: w(3x3),stride = 1,pad = 'same,fmaps = 64   ([-1,8,8,64])\n",
    "    POOL2: p(2x2),stride = 2,pad = 'same'\n",
    "    RELU,Reshape                                      ([-1,8*8*64])\n",
    "    \n",
    "    DENSE1: fmaps = 1024                               ([-1,1024])\n",
    "    RELU\n",
    "    Dropout\n",
    "    \n",
    "    DENSE2: fmaps = 62                                   ([-1,62])\n",
    "    Softmax\n",
    "\"\"\"\n",
    "# 定义输入\n",
    "x = tf.placeholder(tf.float32,[None,32,32,1],'x')\n",
    "y_ = tf.placeholder(name=\"y_\", shape=[None, 62],dtype=tf.float32)\n",
    "\n",
    "# 第一层卷积层 32x32 to 16x16 ， fmaps = 32\n",
    "CONV1 = tf.layers.conv2d(x,32,5,padding='same',activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                         name='CONV1')\n",
    "POOL1 = tf.layers.max_pooling2d(CONV1,2,2,padding='same',name='POOL1')\n",
    "\n",
    "# 第二层卷积层 16x16 to 8x8, fmaps =64\n",
    "CONV2 = tf.layers.conv2d(POOL1,64,5,padding='same',activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                         name='CONV2')\n",
    "POOL2 = tf.layers.max_pooling2d(CONV2,2,2,padding='same',name='POOL2')\n",
    "\n",
    "# 第三层全连接层 8x8x64 to 1024  , fmaps = 1024\n",
    "flat = tf.reshape(POOL2,[-1,8*8*64]) # 平铺特征图\n",
    "DENSE1 = tf.layers.dense(flat,1024,activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                         name='DENSE1')\n",
    "# dropout\n",
    "drop_rate = tf.placeholder(dtype=tf.float32,name='drop_rate')\n",
    "DP = tf.layers.dropout(DENSE1,rate=drop_rate,name='DROPOUT')\n",
    "\n",
    "# softmax 1024 to 10 , fmaps = 10\n",
    "DENSE2 = tf.layers.dense(DP,62,activation=tf.nn.softmax,\n",
    "                         kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                         name='DENSE2')\n",
    "# 定义损失函数\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_,logits=DENSE2))#交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(DENSE2)) #计算交叉熵\n",
    "\n",
    "# 优化器\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy) #使用adam优化器来以0.0001的学习率来进行微调\n",
    "\n",
    "# 准确率测试\n",
    "correct_prediction = tf.equal(tf.argmax(DENSE2,1), tf.argmax(y_,1)) #判断预测标签和实际标签是否匹配\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "# 保存模型\n",
    "saver = tf.train.Saver(var_list=[var for var in tf.trainable_variables()])\n",
    "\n",
    "# 数据集读取\n",
    "# 读取TFR,不打乱文件顺序，指定数据类型，开启多线程\n",
    "[data,label,num] = TFRtools.ReadFromTFRecord(sameName= r'.\\TFR\\CODE_TRAIN-*',isShuffle= True,datatype= tf.float64,labeltype= tf.uint8,)\n",
    "# 批量处理，送入队列数据，指定数据大小，不打乱数据项，设置批次大小32\n",
    "[data_batch,label_batch,num_batch] = TFRtools.DataBatch(data,label,num,dataSize= 32*32,labelSize= 62,isShuffle= True,batchSize= 62)\n",
    "# 修改格式\n",
    "data_batch = tf.cast(tf.reshape(data_batch,[-1,32,32,1]),tf.float32)\n",
    "label_batch = tf.cast(label_batch,tf.float32)\n",
    "\n",
    "\n",
    "ACC = []\n",
    "\n",
    "# 建立会话\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 创建相关目录\n",
    "    GEN_DIR()\n",
    "\n",
    "    # 初始化变量\n",
    "    init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "\n",
    "    # 开启协调器\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动线程\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for step in range(20001):\n",
    "\n",
    "        # 获取批数据\n",
    "        TDB = sess.run([data_batch,label_batch,num_batch])\n",
    "\n",
    "\n",
    "        # 训练\n",
    "        sess.run(train_step,feed_dict={x:TDB[0],\n",
    "                                       y_:TDB[1],\n",
    "                                       drop_rate:0.5})\n",
    "        # 测试\n",
    "        if step%20 == 0:\n",
    "            loss , train_acc = sess.run([cross_entropy,accuracy],feed_dict={x:TDB[0],\n",
    "                                                     y_:TDB[1],\n",
    "                                                     drop_rate:0.0})\n",
    "            \n",
    "            print('step：%d  Loss:%.3f Acc：%.3f  Lr:%f'%(step,loss,train_acc,lr))\n",
    "            f =  open(\"./trainLog/log_20191001交叉熵.txt\", \"a\")\n",
    "            f.write('step：%d  Loss:%.3f Acc：%.3f  Lr:%f \\n'%(step,loss,train_acc,lr) )\n",
    "            f.close()\n",
    "\n",
    "        # 保存模型\n",
    "        if step % 1000 == 0 and step!=0:\n",
    "            lr = lr * 0.7\n",
    "            saver.save(sess, './ckpt/CNN.ckpt', global_step=step)\n",
    "            \n",
    "\n",
    "    # 关闭线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "import TFRtools\n",
    "import pickle\n",
    "\n",
    "tf.reset_default_graph()\n",
    "lr = 1e-4\n",
    "# 生成相关目录保存生成信息\n",
    "def GEN_DIR():\n",
    "    import os\n",
    "    if not os.path.isdir('ckpt'):\n",
    "        print('文件夹ckpt未创建，现在在当前目录下创建..')\n",
    "        os.mkdir('ckpt')\n",
    "    if not os.path.isdir('trainLog'):\n",
    "        print('文件夹ckpt未创建，现在在当前目录下创建..')\n",
    "        os.mkdir('trainLog')\n",
    "\n",
    "\"\"\"\n",
    "#********************* CNN架构 *********************************\n",
    "\n",
    "输入：\n",
    "    x:[-1,32,32,1] 输入图像\n",
    "    y_:[-1,62]     标签\n",
    "CNN:\n",
    "    CONV1: w(3x3),stride = 1,pad = 'same',fmaps = 32 ([-1,16,16,32])\n",
    "    POOL1: p(2x2),stride = 2,pad = 'same'\n",
    "    RELU\n",
    "    \n",
    "    CONV2: w(3x3),stride = 1,pad = 'same,fmaps = 64   ([-1,8,8,64])\n",
    "    POOL2: p(2x2),stride = 2,pad = 'same'\n",
    "    RELU,Reshape                                      ([-1,8*8*64])\n",
    "    \n",
    "    DENSE1: fmaps = 1024                               ([-1,1024])\n",
    "    RELU\n",
    "    Dropout\n",
    "    \n",
    "    DENSE2: fmaps = 62                                   ([-1,62])\n",
    "    Softmax\n",
    "\"\"\"\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    # 定义输入\n",
    "    x = tf.placeholder(tf.float32,[None,32,32,1],name = 'x')\n",
    "    y_ = tf.placeholder(name=\"y_\", shape=[None, 62],dtype=tf.float32)\n",
    "with tf.name_scope(\"layers\"):\n",
    "\n",
    "    # 第一层卷积层 32x32 to 16x16 ， fmaps = 32\n",
    "    CONV1 = tf.layers.conv2d(x,32,5,padding='same',activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                             name='CONV1')\n",
    "    POOL1 = tf.layers.max_pooling2d(CONV1,2,2,padding='same',name='POOL1')\n",
    "\n",
    "    # 第二层卷积层 16x16 to 8x8, fmaps =64\n",
    "    CONV2 = tf.layers.conv2d(POOL1,64,5,padding='same',activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                             name='CONV2')\n",
    "    POOL2 = tf.layers.max_pooling2d(CONV2,2,2,padding='same',name='POOL2')\n",
    "\n",
    "    # 第三层全连接层 8x8x64 to 1024  , fmaps = 1024\n",
    "    flat = tf.reshape(POOL2,[-1,8*8*64]) # 平铺特征图\n",
    "    DENSE1 = tf.layers.dense(flat,1024,activation=tf.nn.relu,\n",
    "                             kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                             name='DENSE1')\n",
    "    # dropout\n",
    "    drop_rate = tf.placeholder(dtype=tf.float32,name='drop_rate')\n",
    "    DP = tf.layers.dropout(DENSE1,rate=drop_rate,name='DROPOUT')\n",
    "\n",
    "    # softmax 1024 to 10 , fmaps = 10\n",
    "    DENSE2 = tf.layers.dense(DP,62,activation=tf.nn.softmax,\n",
    "                             kernel_initializer=tf.random_normal_initializer(0,0.1),\n",
    "                             name='softmax')\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    # 定义损失函数\n",
    "     #计算交叉熵\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(DENSE2))\n",
    "    tf.summary.scalar(\"loss\",cross_entropy)\n",
    "with tf.name_scope(\"train\"):\n",
    "    # 梯度下降\n",
    "    train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy) #使用adam优化器来以0.0001的学习率来进行微调\n",
    "\n",
    "# 准确率测试\n",
    "correct_prediction = tf.equal(tf.argmax(DENSE2,1), tf.argmax(y_,1)) #判断预测标签和实际标签是否匹配\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "tf.summary.scalar(\"accuracy\",accuracy)\n",
    "\n",
    "# 保存模型\n",
    "saver = tf.train.Saver(var_list=[var for var in tf.trainable_variables()])\n",
    "\n",
    "# 数据集读取\n",
    "# 读取TFR,不打乱文件顺序，指定数据类型，开启多线程\n",
    "[data,label,num] = TFRtools.ReadFromTFRecord(sameName= r'.\\TFR\\CODE_TRAIN-*',isShuffle= False,datatype= tf.float64,labeltype= tf.uint8,)\n",
    "# 批量处理，送入队列数据，指定数据大小，不打乱数据项，设置批次大小32\n",
    "[data_batch,label_batch,num_batch] = TFRtools.DataBatch(data,label,num,dataSize= 32*32,labelSize= 62,isShuffle= False,batchSize= 32)\n",
    "# 修改格式\n",
    "data_batch = tf.cast(tf.reshape(data_batch,[-1,32,32,1]),tf.float32)\n",
    "label_batch = tf.cast(label_batch,tf.float32)\n",
    "\n",
    "\n",
    "ACC = []\n",
    "\n",
    "# 建立会话\n",
    "merged = tf.summary.merge_all()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 创建相关目录\n",
    "    GEN_DIR()\n",
    "    # 初始化变量\n",
    "    init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"./logs/\", sess.graph)\n",
    "    # 开启协调器\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动线程\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for step in range(20000):\n",
    "\n",
    "        # 获取批数据\n",
    "        TDB = sess.run([data_batch,label_batch,num_batch])\n",
    "\n",
    "\n",
    "        # 训练\n",
    "        _,summary = sess.run([train_step,merged],feed_dict={x:TDB[0],\n",
    "                                       y_:TDB[1],\n",
    "                                       drop_rate:0.5})\n",
    "        # 测试\n",
    "        if step%10 == 0:\n",
    "            train_acc = sess.run(accuracy,feed_dict={x:TDB[0],\n",
    "                                                     y_:TDB[1],\n",
    "                                                     drop_rate:0.0})\n",
    "            ACC.append(train_acc)\n",
    "            writer.add_summary(summary,step)\n",
    "            print('迭代次数：%d..准确率：%.3f'%(step,train_acc))\n",
    "\n",
    "        # 保存模型\n",
    "        if step % 1000 == 0 and step!=0:\n",
    "            lr = lr * 0.6\n",
    "#             saver.save(sess, './ckpt/CNN.ckpt', global_step=step)\n",
    "\n",
    "    # 关闭线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "print (\"done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
